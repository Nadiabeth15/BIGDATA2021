{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496d0711",
   "metadata": {},
   "source": [
    "## TAREA MapReduce - MINERÍA DE DATOS\n",
    "**Estudiante:** Nadiabeth Diana Mallqui Apaza    \n",
    "**Código:** 171063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61f7ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la librería \"findspark\"\n",
    "import findspark\n",
    "# \"findspark.init()\" permite que pyspark se pueda importar como una biblioteca regular.\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de76904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la librerías a utilizar\n",
    "import math\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark_session = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc77df",
   "metadata": {},
   "source": [
    "#### **Lectura de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e640b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos nuestro archivo de texto\n",
    "data = sc.textFile(\"prueba.txt\")\n",
    "# Lo almacenamos en lines para que pueda ser iterable\n",
    "lines = data.collect()\n",
    "# Creamos una lista donde almacenaremos cada linea u oración del archivo\n",
    "sentences =[]\n",
    "for line in lines:\n",
    "    if (line != \"\"): # Sin las lineas vacías\n",
    "        sentences.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af2d203b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------------+\n",
      "|label|sentence                                                                           |\n",
      "+-----+-----------------------------------------------------------------------------------+\n",
      "|0    |protester stage diein protest store nyc anger misplace retweet agree               |\n",
      "|1    |apple intraday comment update range premium user aapl stockaction trading stock mkt|\n",
      "|2    |ios app 2014 name elevate brain training iphone app                                |\n",
      "|3    |shit                                                                               |\n",
      "|4    |founder attack boss ridiculous comment ad                                          |\n",
      "|5    |evidence factcheckthis                                                             |\n",
      "|6    |educate                                                                            |\n",
      "|7    |hard reach buy suicide squad comic_strip apple store turkey                        |\n",
      "|8    |delete music customer ipod                                                         |\n",
      "|9    |apple intraday comment update range premium user aapl stockaction trading stock mkt|\n",
      "|10   |studio 45,000 outlet computer need battery future                                  |\n",
      "|11   |apple great business aapl investwall aapl                                          |\n",
      "|12   |dear love iphone plus lot great achievement iphone reboot day fail                 |\n",
      "|13   |survey feedback iwatch positioning fashion accessory geek centric gadget           |\n",
      "|14   |similar cloud backup picture onlinefootprint modicumofprudence                     |\n",
      "|15   |protester stage diein protest store nyc anger misplace retweet agree               |\n",
      "|16   |fuck make shit product                                                             |\n",
      "|17   |try turn problem                                                                   |\n",
      "|18   |macbook pro annoying asus window computer freezing laggy etc excellence            |\n",
      "|19   |speak wearable new chargehr amp iphone want eat latke run place tl_chat            |\n",
      "+-----+-----------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos otra lista para almacenar los documentos\n",
    "documents = []\n",
    "for i in range(0,len(sentences)):\n",
    "    documents.append((i,sentences[i]))\n",
    "# Crearemos un DataFrame para mostrar los documentos con sus respectivos labels\n",
    "documentsData = spark_session.createDataFrame(documents, [\"label\", \"sentence\"]) \n",
    "# Mostramos los documentos en DataFrame\n",
    "documentsData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4c907",
   "metadata": {},
   "source": [
    "### **BoW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8db311be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 'protest'), 1),\n",
       " ((0, 'anger'), 1),\n",
       " ((0, 'misplace'), 1),\n",
       " ((0, 'retweet'), 1),\n",
       " ((1, 'range'), 1),\n",
       " ((1, 'user'), 1),\n",
       " ((1, 'trading'), 1),\n",
       " ((1, 'stock'), 1),\n",
       " ((1, 'mkt'), 1),\n",
       " ((2, '2014'), 1),\n",
       " ((2, 'name'), 1),\n",
       " ((6, 'educate'), 1),\n",
       " ((7, 'buy'), 1),\n",
       " ((7, 'apple'), 1),\n",
       " ((8, 'delete'), 1),\n",
       " ((8, 'music'), 1),\n",
       " ((9, 'range'), 1),\n",
       " ((9, 'user'), 1),\n",
       " ((9, 'trading'), 1),\n",
       " ((9, 'stock'), 1),\n",
       " ((9, 'mkt'), 1),\n",
       " ((10, '45,000'), 1),\n",
       " ((11, 'apple'), 1),\n",
       " ((12, 'love'), 1),\n",
       " ((13, 'geek'), 1),\n",
       " ((14, 'onlinefootprint'), 1),\n",
       " ((15, 'agree'), 1),\n",
       " ((16, 'fuck'), 1),\n",
       " ((16, 'make'), 1),\n",
       " ((16, 'shit'), 1),\n",
       " ((18, 'asus'), 1),\n",
       " ((18, 'freezing'), 1),\n",
       " ((18, 'laggy'), 1),\n",
       " ((18, 'excellence'), 1),\n",
       " ((19, 'amp'), 1),\n",
       " ((19, 'iphone'), 1),\n",
       " ((19, 'want'), 1),\n",
       " ((19, 'eat'), 1),\n",
       " ((19, 'place'), 1),\n",
       " ((20, 'class'), 1),\n",
       " ((21, 'ability'), 1),\n",
       " ((22, 'aapl'), 1),\n",
       " ((22, '2014'), 1),\n",
       " ((23, 'robertson'), 1),\n",
       " ((23, 'bullish'), 1),\n",
       " ((23, 'apple'), 1),\n",
       " ((24, 'update'), 1),\n",
       " ((25, 'hold'), 1),\n",
       " ((25, 'scanner'), 1),\n",
       " ((25, 'credit'), 1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paraleliazmos nuestro data\n",
    "lines=sc.parallelize(documents)\n",
    "# Recupera todos los elementos del lines\n",
    "lines.collect()\n",
    "map1=lines.flatMap(lambda x: [((x[0],i),1) for i in x[1].split()])\n",
    "# Recupera todos los elementos del map1\n",
    "map1.collect()\n",
    "#Map Reduce\n",
    "reduce=map1.reduceByKey(lambda x,y:x+y)\n",
    "#BOG de las 4 oraciones\n",
    "reduce.reduceByKey(lambda x,y:x+y).take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5303cc5",
   "metadata": {},
   "source": [
    "### Algoritmo TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6be4617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+---+------------------+------------------+\n",
      "|DocumentId|        Token| TF|               IDF|            TF-IDF|\n",
      "+----------+-------------+---+------------------+------------------+\n",
      "|         0|        store|  1|0.9777236052888477|0.9777236052888477|\n",
      "|         0|        diein|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         0|      retweet|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         0|        agree|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         0|        stage|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         0|          nyc|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         0|    protester|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         0|      protest|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         0|        anger|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         0|     misplace|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         1|        range|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         1|      trading|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         1|        stock|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         1|          mkt|  1|0.9777236052888477|0.9777236052888477|\n",
      "|         1|       update|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         1|        apple|  1|0.5797835966168101|0.5797835966168101|\n",
      "|         1|     intraday|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         1|      premium|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         1|         aapl|  1|0.6255410871774852|0.6255410871774852|\n",
      "|         1|  stockaction|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         1|         user|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         1|      comment|  1|0.9777236052888477|0.9777236052888477|\n",
      "|         2|         2014|  1|1.2787536009528289|1.2787536009528289|\n",
      "|         2|          ios|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         2|          app|  2|1.5797835966168101|3.1595671932336202|\n",
      "|         2|         name|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         2|        brain|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         2|      elevate|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         2|     training|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         2|       iphone|  1|1.1026623418971477|1.1026623418971477|\n",
      "|         3|         shit|  1|1.2787536009528289|1.2787536009528289|\n",
      "|         4|         boss|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         4|   ridiculous|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         4|      comment|  1|0.9777236052888477|0.9777236052888477|\n",
      "|         4|      founder|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         4|       attack|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         4|           ad|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         5|factcheckthis|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         5|     evidence|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         6|      educate|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         7|        store|  1|0.9777236052888477|0.9777236052888477|\n",
      "|         7|  comic_strip|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         7|      suicide|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         7|          buy|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         7|        apple|  1|0.5797835966168101|0.5797835966168101|\n",
      "|         7|         hard|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         7|        reach|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         7|        squad|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         7|       turkey|  1|1.5797835966168101|1.5797835966168101|\n",
      "|         8|     customer|  1|1.5797835966168101|1.5797835966168101|\n",
      "+----------+-------------+---+------------------+------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Almacenamos en la variable data los documentos a tratar\n",
    "data= documents\n",
    "lines=sc.parallelize(data)\n",
    "lines.collect()\n",
    "\n",
    "# Asignamos nuestro valor existente a un nuevo par clave-valor que comprende:\n",
    "    # - ID de documento\n",
    "    # - token como clave\n",
    "    # - 1 (que representa el recuento) como valor\n",
    "    \n",
    "# Usaremos \"flatMap\" para combinar todos los tokens en una sola lista\n",
    "map_1 = lines.flatMap(lambda x: [((x[0],i),1) for i in x[1].split()])\n",
    "map_1.collect()\n",
    "\n",
    "# Agrupamos los pares clave con la clave común y agregaremos los valores \n",
    "# de la misma clave para obtener la frecuencia del término (TF)\n",
    "reduce = map_1.reduceByKey(lambda x,y:x+y)\n",
    "reduce.collect()\n",
    "\n",
    "# Realizamos un nuevo mapeo\n",
    "TF = reduce.map(lambda x: (x[0][1],(x[0][0],x[1])))\n",
    "TF.collect()\n",
    "\n",
    "# Calculamos la frecuencia inversa de documentos (IDF)\n",
    "\n",
    "# Primero, asignamos el valor anterior a un nuevo par clave \n",
    "    # Donde: \n",
    "    # la clave será el token \n",
    "    # su valor será el identificador TF del documento\n",
    "map_3 = reduce.map(lambda x: (x[0][1],(x[0][0],x[1],1)))\n",
    "map_3.collect()\n",
    "\n",
    "# Luego, extraemos el token y el número de contador\n",
    "map_4 = map_3.map(lambda x:(x[0],x[1][2]))\n",
    "map_4.collect()\n",
    "\n",
    "# Por último, reducimos por clave para obtener el recuento de documentos \n",
    "# que contienen un token i particular \n",
    "reduce_2 = map_4.reduceByKey(lambda x,y:x+y)\n",
    "reduce_2.collect()\n",
    "\n",
    "# Así obtenemos el (IDF)\n",
    "IDF = reduce_2.map(lambda x: (x[0],math.log10(len(data)/x[1])))\n",
    "IDF.collect()\n",
    "\n",
    "# Calculamos el (TF-IDF)\n",
    "\n",
    "# Ya que tenemos dos RDD's realizaremos una combinación interna para asignar \n",
    "# a cada token una identificación de documento, TF y puntuación IDF.\n",
    "RDD = TF.join(IDF)\n",
    "RDD.collect()\n",
    "\n",
    "# Multiplicamos el TF e IDF de cada token asociado con la identificación del documento respectivo\n",
    "RDD = RDD.map(lambda x: (x[1][0][0],(x[0],x[1][0][1],x[1][1],x[1][0][1]*x[1][1]))).sortByKey()\n",
    "RDD.collect()\n",
    "\n",
    "# Por último, convertimos la salida final a un marco de datos de Pyspark para visualizar las \n",
    "# puntuaciones con mayor claridad\n",
    "RDD = RDD.map(lambda x: (x[0],x[1][0],x[1][1],x[1][2],x[1][3]))\n",
    "hasattr(RDD, \"toDF\")\n",
    "RDD.toDF([\"DocumentId\",\"Token\",\"TF\",\"IDF\",\"TF-IDF\"]).show(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
